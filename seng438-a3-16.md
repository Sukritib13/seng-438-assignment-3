**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 â€“ Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#: 16   |     |
| -------------- | --- |
| Student Names: | Sahib Singh Thethi |
|                | Sukriti Badhwar |
|                | Wade Banman |
|                | Rohan Lange |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

With a focus on code coverage as a gauge of test suite adequacy, our team's third assignment aimed to improve our comprehension and use of white-box testing methodologies. Using control-flow and data-flow coverage criteria, this assignment changed our methodology from requirements-based test generation to coverage-based test generation, building on the unit testing abilities we acquired in Assignment 2. As our System Under Test (SUT), we used the open-source Java charting package JFreeChart framework, focusing on the org.jfree.data.DataUtilities and org.jfree.data.Range classes. EclEmma, which was incorporated into Eclipse, served as our main instrument for evaluating control-flow coverage. It enabled us to evaluate the statement, branch, and method coverage of our test suite. Through this process, we improved our comprehension of the relationship between coverage metrics and test effectiveness while investigating the usefulness, drawbacks, and practical implementation of coverage tools. This report highlights our team's efforts to enhance the JFreeChart test suite and assess the trade-offs between various testing methodologies. It also describes our approach, results, and views on the process.

# 2 Manual data-flow coverage calculations for X and Y methods

## **DataUtilities Class - calculateColumnTotal()**

<img src="media/DFG-of-calculateColumnTotal.jpg"  width="360"/>

**Def-Use Sets:**

|  **Node** |    **Def**   |       **Use**       |
|-----------|--------------|---------------------|
|   1       | data, column |          -          |
|   2       |       -      |         data        |
|   3       |     total    |          -          |
|   4       |   rowCount   |         data        |
|   5       |       r      |     r, rowCount     |
|   6       |       n      |  data, r, column, n |
|   7       |     total    |       total, n      |
|   8       |       -      |          r          |
|   9       |      r2      |     r2, rowCount    |
|  10       |       n      | data, r2, column, n |
|  11       |     total    |       total, n      |
|  12       |       -      |          r2         |
|  13       |       -      |        total        |

**DU-pairs:**

| **Variable** |                                 **DU Pair**                                |
|----------|------------------------------------------------------------------------|
| data     | (1,2), (1,4), (1,6), (1,10)                                            |
| column   | (1, 6), (1,10)                                                         |
| total    | (3, 7), (7, 11), (11, 13), (3, 11), (7, 13), (3, 13), (7, 7), (11, 11) |
| rowCount | (4, 5), (4, 9)                                                         |
| r        | (5, 5), (5, 6), (5, 8)                                                 |
| r2       | (9, 9), (9, 10), (9, 12)                                               |
| n        | (6, 6), (6, 7), (10, 10), (10, 11)                                     |

**Test Cases Coverage:**

|                   Test Cases                   |                                                                                            Pairs Covered                                                                                            |
|:----------------------------------------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| calculateColumnTotalForMultipleRows()          | (1, 2), (1, 4), (1, 6), (1, 10), (1, 6), (1, 10), (3, 7), (7, 11), (11, 13), (7, 7), (11, 11), (4, 5), (4, 9), (5, 5), (5, 6), (5, 8), (9, 9), (9, 10), (9, 12), (6, 6), (6, 7), (10, 10), (10, 11) |
| calculateColumnTotalForSingleRowSingleColumn() | (1, 2), (1, 4), (1, 6), (1, 10), (1, 6), (1, 10), (3, 7), (7, 11), (11, 13), (7, 7), (11, 11), (4, 5), (4, 9), (5, 5), (5, 6), (5, 8), (9, 9), (9, 10), (9, 12), (6, 6), (6, 7), (10, 10), (10, 11) |
| calculateColumnTotalForNegativeValues()        | (1, 2), (1, 4), (1, 6), (1, 10), (1, 6), (1, 10), (3, 7), (7, 11), (11, 13), (7, 7), (11, 11), (4, 5), (4, 9), (5, 5), (5, 6), (5, 8), (9, 9), (9, 10), (9, 12), (6, 6), (6, 7), (10, 10), (10, 11) |
| calculateColumnTotalForNullValue()             | (1, 2), (1, 4), (1, 6), (1, 10), (1, 6), (1, 10), (3, 7), (7, 11), (11, 13), (7, 7), (11, 11), (4, 5), (4, 9), (5, 5), (5, 6), (5, 8), (9, 9), (9, 10), (9, 12), (6, 6), (6, 7), (10, 10), (10, 11) |
| calculateColumnTotalForEmptyTable()            | (1, 2), (1, 4), (3, 13), (4, 5), (4, 9), (5, 5), (9, 9)                                                                                                                                             |
| calculateColumnTotalForNullData()              | (1, 2)                                                                                                                                                                                              |
| calculateColumnTotalForColumnOutOfBounds()     | (1, 2), (1, 4), (3, 13), (4, 5), (4, 9), (5, 5), (9, 9)                                                                                                                                             |
| calculateColumnTotalForNegativeColumnIndex()   | (1, 2), (1, 4), (3, 13), (4, 5), (4, 9), (5, 5), (9, 9)                                                                                                                                             |

**DU pair Coverage:**

DU pair coverage = (Covered DU-pairs) / (Total DU-pairs) = (24 / 26) x 100 = 92.31%

## **Range Class - shift()**
<img src="media/DFG-of-shift.jpg"  width="360"/>

**Def-Use Sets:**

|   **Node**  |             **Def**              |       **Use**       |
|-------------|----------------------------------|---------------------|
|      1      |  base, delta, allowZeroCrossing  |         -           |
|      2      |                -                 |        base         |
|      3      |                -                 |  allowZeroCrossing  |
|      4      |                -                 |    base, delta      |
|     5/9     |                -                 |        base         |
|    6/10     |                -                 |    base, delta      |
|     7/11    |                -                 |    base, delta      |
|     8/12    |                -                 |    base, delta      |


**DU-pairs:**

| **Variable**        |                                 **DU Pair**                            |
|---------------------|------------------------------------------------------------------------|
| base                |  (1, 2) (1, 4) (1, 5/9) (1, 6/10) (1, 7/11) (1, 8/12)     |
| delta               |  (1, 4) (1, 6/10) (1, 7/11) (1, 8/12)                           |
| allowZeroCrossing   |  (1, 8/12)                                                            |

**Test Cases Coverage:**
 
|                         **Test Cases**                              |                             **Pairs Covered**                              |
|:-------------------------------------------------------------------:|:--------------------------------------------------------------------------:|
|testPositiveDeltaValueWithNoZeroCrossingAndZeroCrossingFalseForShift | (1,3), (1,5/9), (1,6/10), (1,7/11), (1,6/10), (1,7/11), (1,2)|
|testNegativeDeltaValueWithNoZeroCrossingAndZeroCrossingFalseForShift | (1,3), (1,5/9), (1,6/10), (1,7/11), (1,6/10), (1,7/11), (1,2)|
|testPositiveDeltaValueWithNoZeroCrossingAndZeroCrossingTrueForShift  | (1,3), (1,4), (1,4), (1,2)                                 |
|testNegativeDeltaValueWithNoZeroCrossingAndZeroCrossingTrueForShift  | (1,3), (1,4), (1,4), (1,2)                                 |
|testNegativeDeltaValueWithZeroCrossingFalseForShift                  | (1,3), (1,5/9), (1,6/10), (1,7/11), (1,6/10), (1,7/11), (1,2)|
|testPositiveDeltaValueWithZeroCrossingFalseForShift                  | (1,3), (1,5/9), (1,6/10), (1,7/11), (1,6/10), (1,7/11), (1,2)|
|testNegativeDeltaValueWithZeroCrossingTrueForShift                   | (1,3), (1,4), (1,4), (1,2)                                 |
|testPositiveDeltaValueWithZeroCrossingTrueForShift                   | (1,3), (1,4), (1,4), (1,2)                                 |
|testZeroDeltaValueWithZeroCrossingFalseForShift                      | (1,3), (1,5/9), (1,6/10), (1,7/11), (1,6/10), (1,7/11), (1,2)|
|testZeroDeltaValueWithZeroCrossingTrueForShift                       | (1,3), (1,4), (1,4), (1,2)                                 |
|testExceptionWhenNullRangePassedForShift                             | (1,2)                                                                  |

**DU pair Coverage:**

DU pair coverage = (Covered DU-pairs) / (Total DU-pairs) = (9 / 11) x 100 = 81.8%
# 3 A detailed description of the testing strategy for the new unit test
Our testing strategy focused on systematically improving branch, statement, and method coverage for the Range and DataUtilities classes. To achieve this, we analyzed our initial test cases from Assignment 2, identified gaps in coverage, and developed new test cases targeting untested methods and uncovered branches.

1. Coverage Analysis and Test Planning
- We began by assessing our existing unit tests to determine our current branch, statement, and method coverage using EclEmma, which integrates well with Eclipse.
- By reviewing the source code directly, we identified missing test partitions and uncovered paths, rather than solely relying on method requirements.
- We examined Javadoc documentation to find methods we had not previously tested, ensuring that every method was evaluated.
 
2. Test Case Development
- For previously untested methods for example - clone(), equal() etc., we designed test cases that covered edge cases, boundary values, and critical execution paths.
- We also revisited previously tested methods from Assignment 2, refining our approach to enhance coverage by including additional test scenarios.

3. Execution and Improvement
- Using EclEmma, we identified specific lines, branches, and conditions that were still uncovered and adjusted our tests accordingly.
- We divided test cases based on the classes to collaboratively design and implement new test cases, ensuring accuracy and completeness.

By implementing above steps, we successfully increased our coverage metrics to required numbers and ensured more robust testing for Range and DataUtilities classes.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

1. **`testGetCumulativePercentagesWithNullValues()`** for `getCumulativePercentages()`:

- This test case is designed to verify the behavior of the getCumulativePercentages() method when the input data contains null values. The purpose of this test is to ensure that the method correctly handles missing values without affecting the overall calculation of cumulative percentages.
- Impact on Code Coverage:
    - Branch Coverage: Increased from 58.3% to 75% by testing paths involving null values.
    - Statement Coverage: Maintained at 83.3%, confirming execution of all relevant lines of code.
    - Method Coverage: Remains at 100%, ensuring the method is fully tested.
- This test case strengthens the robustness of the getCumulativePercentages() method by verifying its handling of missing data, ensuring correctness under real-world conditions.

2. **`calculateColumnTotalWithValidRows()`** for `calculateColumnTotal(Values2D data, int column, int[] validRows)`:
- This test case is designed to verify the behavior of the calculateColumnTotal() method when provided with a Values2D dataset and a specified set of valid row indices. The purpose of this test is to ensure that the method correctly sums the values in the given column while considering only the specified valid rows. The original coverage of this method was 0% as we did not test this method previously during black box testing.
- Impact on Code Coverage:
    - Branch Coverage: Increased from 0% to 62.5% by testing the path where all provided rows are valid and contain non-null values.
    - Statement Coverage: Increased from 0% to 91.7% ensuring execution of all relevant lines, including row iteration and value summation.
    - Method Coverage: Increased from 0% to 100% leading to full coverage of calculateColumnTotal(), verifying its expected functionality.
      
  Note: 100% coverage could not be attained due to unreachable or dead code
- This test case strengthens the robustness of the calculateColumnTotal() method by confirming that it accurately computes the total when given a complete set of valid rows, ensuring correctness in structured tabular calculations.


3. **`testgetCentralvalue()`** for `getCentralvalue()`:

- This test is used to test the first if statement inside the getCentralValue() method. The purpose of this test is to make sure the method itself is actually tested as before it was not. Making sure the proper central value is really returned
- Impact on Code Coverage:
    - Branch Coverage: Remains at 89%
    - Statement Coverage: Maintained at 91.9% to 92.4%
    - Instruction Coverage: Increaseed from 86.6% to 88.4%
- This test case strengthens the coverage of the overall class as before it was left untested.

4. **`testShiftingZeroWithZeroCrossingFalse()`** for `shift()`:

- This test cases is designed to test that the shift() method correctly applies the expected shift to ranges with 0 on either bound (the boundary between positive abnd negative numbers) specifically when zero crossing is turned off
- Impact on Code Coverage:
    - Branch Coverage: Increased from 87.8% to 89.0% by testing paths including 0 as a boundary.
    - Instruction Coverage: Increased from 87.7% at 88.4%, by testing paths including 0 as a boundary.
    - Statement Coverage: Increased from 91.8% at 92.0%, by testing paths including 0 as a boundary.
- This test helps to improve the robustness of the shift() method by ensuring it behaves properly on the boundaries of its range inputs

5. **`testHashcode()`** for `hashcode()`:

- This test cases is designed to test that the shift() method correctly applies the expected shift to ranges with 0 on either bound (the boundary between positive abnd negative numbers) specifically when zero crossing is turned off
- Impact on Code Coverage:
    - Branch Coverage: Remains at 89.0% as there are no branches within the hashcode method.
    - Instruction Coverage: Increased from 84.3% at 88.4%, by testing paths including 0 as a boundary.
    - Statement Coverage: Increased from 87.6% at 92.0%, by testing paths including 0 as a boundary.
- This test helps to improve the robustness of the shift() method by ensuring it behaves properly on the boundaries of its range inputs




# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

## Range Class


| | **Before** | **After** |
|-|------------|-----------|
| Instruction| <img src="media/RangeClassInstructionBefore.png"  width="360"/> | <img src="media/RangeClassInstructionAfter.png"  width="360"/> |
| Branch | <img src="media/RangeClassBranchBefore.png"  width="360"/> | <img src="media/RangeClassBranchAfter.png"  width="360"/> |
|Line |<img src="media/RangeClassLineBefore.png"  width="360"/>| <img src="media/RangeClassLineAfter.png"  width="360"/> |



# 6 Pros and Cons of coverage tools used and Metrics you report

In our assignment, we used EclEmma as our code coverage tool. It was selected because of its smooth Eclipse integration, which makes it simple to use and set up. Although EclEmma did not offer condition coverage, it did enable us to measure statement, branch, and method coverage. Its visual feedback technique, which displayed uncovered code in red and covered code in green, was one of its most helpful features. Because of this, it was simpler to find areas where our test coverage was lacking and adjust our unit tests appropriately. We were also able to keep the majority of our initial tests while performing white-box testing to increase coverage because EclEmma was compatible with mock objects.

However, EclEmma had some limitations. One major drawback was that it did not support condition coverage, which would have allowed us to analyze individual Boolean subconditions within decision statements. Additionally, the tool did not account for dead or unreachable code, which affected our overall coverage percentage. For example, in the DataUtilities class, our statement coverage was 89.6% instead of reaching 90% because EclEmma still considered logically unreachable code in its calculations.

In terms of reported metrics, we primarily focused on statement coverage (percentage of executed statements), branch coverage (percentage of executed control flow branches), and method coverage (percentage of methods executed at least once). These metrics helped us assess test effectiveness and guided improvements in our testing approach. Despite its limitations, EclEmma was a valuable tool for evaluating and improving our test coverage.

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Both coverage and requirment based test generation are important to detect as many issues as possible and ensure that your deployed code is fully functional and meets the users expectations however they each come wioth there own set of advantages, disadvatages and coverage. The advantage of requirement-based testing is that it ensures the developed software alligns with the user's requests and detects functionality that isn't behaving as desired very quickly and can be implemented with minimal understanding of the deployed code .The advantages of coverage-based testing are that it helps to discover bugs that are not on the typical user data path, it dcadn be automated, and can provide a quantatative metric on testing completeness. In terms of disadvantages, coverage-based tests have a tendancy to create redundant tests and can give the illusion of correctness do to high coverage precentages while requirements based tests are likely to not cover all of the code leaving hidden bugs or bugs that are not directly related to requirements and finally can be hard to develop if requirements aren't clear.

# 8 A discussion on how the team work/effort was divided and managed

We split the group work into two pairs for each class. This meant two worked on the Range class while the other worked on Utilities. Each pair was responsible for creating their new tests to add the required coverage. After each pair completed their respective class, we exchanged our work to check and make sure requirments are met. We also had a group text chat to ask for help from one another if someone got stuck. 

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Our team faced a some difficulties during this assignment that put our technical proficiency and collaboration to the test. Integrating EclEmma with our Eclipse setup and making sure it functioned flawlessly with our current test suite from Assignment 2 was a major challenge. At first, we had problems when building the system's packages, which led to problems when utilizing EclEmma. In order to get around this, we looked at compatibility problems for a while before deciding to re-run the Eclipse setup and make sure that every step is done correctly while installing the right libraries and building new packages. We learned from this how crucial it is to check tool compatibility early on and modify our strategy as necessary. Calculating data-flow coverage by hand for the DataUtilities.calculateColumnTotal function presented another difficulty. Because calculateColumnTotal()'s control flow is so intricate, manually tracking DU-pairs was laborious and prone to mistakes. In order to solve this, we divided the assignment into manageable chunks, which increased precision and strengthened our comprehension of data-flow principles. This experience made clear how time-consuming human analysis is and how beneficial automated tools are for larger systems. The limiting of coverage metrics as the only measure of test quality was one of the most important lessons learnt.  Although reaching the desired coverage was a clear objective, we discovered that high coverage was not always effective in identifying flaws, particularly in edge cases that were hidden by inaccessible code.

# 10 Comments/feedback on the lab itself

Building successfully on the groundwork established in Assignment 2, Assignment 3 offered a priceless chance to expand our knowledge of white-box testing and code coverage.  The work was both difficult and gratifying because of the practical viewpoint that the manual computation of data-flow coverage and the hands-on experience with tools like EclEmma provided.  Our efforts were guided by the assignment's well-defined framework, which included tool familiarization, coverage measurement, and test suite development. Overall, the assignment was well-designed to meet its learning objectives, fostering both technical proficiency and critical thinking.
